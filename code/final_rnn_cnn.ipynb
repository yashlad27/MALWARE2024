{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Data Exploration and Preprocessing: Understand the structure of the dataset, preprocess it as needed, and prepare it for modeling.",
   "id": "a9a4e096820acdea"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-20T15:00:50.393982Z",
     "start_time": "2024-04-20T15:00:50.365322Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = '/Users/yashl/PycharmProjects/MALWARE2024/data/combined_data_ag.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data.head(), data.describe(), data.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 735 entries, 0 to 734\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Mnemonic   735 non-null    object\n",
      " 1   Frequency  735 non-null    int64 \n",
      " 2   Label      735 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 17.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  Mnemonic  Frequency  Label\n",
       " 0      out          2      1\n",
       " 1      jae         18      0\n",
       " 2      shl        110      1\n",
       " 3      and         26      0\n",
       " 4      jne          3      0,\n",
       "          Frequency       Label\n",
       " count   735.000000  735.000000\n",
       " mean    116.442177    0.570068\n",
       " std     524.899984    0.495403\n",
       " min       1.000000    0.000000\n",
       " 25%       1.000000    0.000000\n",
       " 50%       5.000000    1.000000\n",
       " 75%      37.500000    1.000000\n",
       " max    7501.000000    1.000000,\n",
       " None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T15:00:50.919400Z",
     "start_time": "2024-04-20T15:00:50.580128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "mnemonic_encoded = encoder.fit_transform(data[['Mnemonic']])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "frequency_scaled = scaler.fit_transform(data[['Frequency']])\n",
    "\n",
    "import numpy as np\n",
    "features = np.concatenate([mnemonic_encoded, frequency_scaled], axis=1)\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "features_df['Label'] = data['Label']\n",
    "\n",
    "features_df.head()"
   ],
   "id": "39c4b0a2345615b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  129  130  131  132  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   133  134  135  136       137  Label  \n",
       "0  0.0  0.0  0.0  0.0  0.000133      1  \n",
       "1  0.0  0.0  0.0  0.0  0.002267      0  \n",
       "2  0.0  0.0  0.0  0.0  0.014533      1  \n",
       "3  0.0  0.0  0.0  0.0  0.003333      0  \n",
       "4  0.0  0.0  0.0  0.0  0.000267      0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T15:00:51.907273Z",
     "start_time": "2024-04-20T15:00:50.921412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = features_df.drop('Label', axis=1)\n",
    "y = features_df['Label']\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "rfe = RFE(estimator=logreg, n_features_to_select=20)  # Let's select top 20 features for simplicity\n",
    "rfe.fit(X, y)\n",
    "selected_features = rfe.support_\n",
    "selected_feature_names = [f\"Feature_{i}\" for i in range(X.shape[1]) if selected_features[i]]\n",
    "\n",
    "selected_feature_names"
   ],
   "id": "8c758fa17ed2c686",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feature_0',\n",
       " 'Feature_4',\n",
       " 'Feature_7',\n",
       " 'Feature_12',\n",
       " 'Feature_13',\n",
       " 'Feature_15',\n",
       " 'Feature_16',\n",
       " 'Feature_17',\n",
       " 'Feature_29',\n",
       " 'Feature_31',\n",
       " 'Feature_44',\n",
       " 'Feature_46',\n",
       " 'Feature_64',\n",
       " 'Feature_72',\n",
       " 'Feature_81',\n",
       " 'Feature_87',\n",
       " 'Feature_90',\n",
       " 'Feature_110',\n",
       " 'Feature_126',\n",
       " 'Feature_137']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T15:00:51.919344Z",
     "start_time": "2024-04-20T15:00:51.908280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "label_encoder = LabelEncoder()\n",
    "data['Mnemonic_encoded'] = label_encoder.fit_transform(data['Mnemonic'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data['Frequency_scaled'] = scaler.fit_transform(data[['Frequency']])\n",
    "\n",
    "data.head()"
   ],
   "id": "c6c1c779ff78587",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Mnemonic  Frequency  Label  Mnemonic_encoded  Frequency_scaled\n",
       "0      out          2      1                92          0.000133\n",
       "1      jae         18      0                53          0.002267\n",
       "2      shl        110      1               123          0.014533\n",
       "3      and         26      0                 6          0.003333\n",
       "4      jne          3      0                62          0.000267"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mnemonic</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Label</th>\n",
       "      <th>Mnemonic_encoded</th>\n",
       "      <th>Frequency_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>out</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jae</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.002267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shl</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0.014533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jne</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T15:00:51.945300Z",
     "start_time": "2024-04-20T15:00:51.921352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "rfe = RFE(estimator=logreg, n_features_to_select=1, step=1)\n",
    "rfe.fit(data[['Mnemonic_encoded', 'Frequency_scaled']], data['Label'])\n",
    "\n",
    "selected_features = pd.DataFrame({\n",
    "    'Feature': ['Mnemonic_encoded', 'Frequency_scaled'],\n",
    "    'Importance': rfe.ranking_\n",
    "})\n",
    "selected_features.sort_values(by='Importance')\n"
   ],
   "id": "1ad7d9f7e7a66c19",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Feature  Importance\n",
       "1  Frequency_scaled           1\n",
       "0  Mnemonic_encoded           2"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frequency_scaled</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mnemonic_encoded</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T15:00:51.987125Z",
     "start_time": "2024-04-20T15:00:51.946307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, GRU, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X = data[['Mnemonic_encoded', 'Frequency_scaled']].values.reshape(-1, 1, 2)\n",
    "y = to_categorical(data['Label'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, input_shape=(1, 2)),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.summary()"
   ],
   "id": "39c2f796c1309792",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashl\\PycharmProjects\\MALWARE2024\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │        \u001B[38;5;34m10,600\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m)              │           \u001B[38;5;34m102\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m10,702\u001B[0m (41.80 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,702</span> (41.80 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m10,702\u001B[0m (41.80 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,702</span> (41.80 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T15:00:56.597615Z",
     "start_time": "2024-04-20T15:00:51.988133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gru_model = Sequential([\n",
    "    GRU(50, input_shape=(1, 2)),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "gru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "gru_model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
    "gru_performance = gru_model.evaluate(X_test, y_test)"
   ],
   "id": "20bbf32f6aae4f1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.4052 - loss: 0.9648 - val_accuracy: 0.5374 - val_loss: 0.6915\n",
      "Epoch 2/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5212 - loss: 0.7347 - val_accuracy: 0.5374 - val_loss: 0.7001\n",
      "Epoch 3/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5804 - loss: 0.7066 - val_accuracy: 0.5374 - val_loss: 0.6995\n",
      "Epoch 4/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5357 - loss: 0.7382 - val_accuracy: 0.5374 - val_loss: 0.6931\n",
      "Epoch 5/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5355 - loss: 0.7356 - val_accuracy: 0.5374 - val_loss: 0.6932\n",
      "Epoch 6/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5371 - loss: 0.7041 - val_accuracy: 0.5374 - val_loss: 0.6970\n",
      "Epoch 7/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5221 - loss: 0.7282 - val_accuracy: 0.5374 - val_loss: 0.6974\n",
      "Epoch 8/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5487 - loss: 0.7057 - val_accuracy: 0.5374 - val_loss: 0.6929\n",
      "Epoch 9/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5513 - loss: 0.6981 - val_accuracy: 0.5374 - val_loss: 0.6943\n",
      "Epoch 10/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5392 - loss: 0.7051 - val_accuracy: 0.5374 - val_loss: 0.6945\n",
      "Epoch 11/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5169 - loss: 0.7411 - val_accuracy: 0.5374 - val_loss: 0.6946\n",
      "Epoch 12/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5370 - loss: 0.7238 - val_accuracy: 0.5374 - val_loss: 0.6938\n",
      "Epoch 13/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5629 - loss: 0.7049 - val_accuracy: 0.5442 - val_loss: 0.6928\n",
      "Epoch 14/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5451 - loss: 0.6990 - val_accuracy: 0.5374 - val_loss: 0.6944\n",
      "Epoch 15/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5164 - loss: 0.7173 - val_accuracy: 0.5374 - val_loss: 0.6957\n",
      "Epoch 16/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5719 - loss: 0.7011 - val_accuracy: 0.5374 - val_loss: 0.6944\n",
      "Epoch 17/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5693 - loss: 0.6947 - val_accuracy: 0.5374 - val_loss: 0.6969\n",
      "Epoch 18/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5364 - loss: 0.7192 - val_accuracy: 0.5442 - val_loss: 0.6933\n",
      "Epoch 19/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5788 - loss: 0.6950 - val_accuracy: 0.5374 - val_loss: 0.6941\n",
      "Epoch 20/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5518 - loss: 0.6919 - val_accuracy: 0.5510 - val_loss: 0.6897\n",
      "Epoch 21/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5619 - loss: 0.6932 - val_accuracy: 0.5374 - val_loss: 0.6977\n",
      "Epoch 22/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5502 - loss: 0.6873 - val_accuracy: 0.5374 - val_loss: 0.6949\n",
      "Epoch 23/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5587 - loss: 0.6996 - val_accuracy: 0.5510 - val_loss: 0.6928\n",
      "Epoch 24/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5497 - loss: 0.6900 - val_accuracy: 0.5510 - val_loss: 0.6926\n",
      "Epoch 25/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5421 - loss: 0.6995 - val_accuracy: 0.5374 - val_loss: 0.6937\n",
      "Epoch 26/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5237 - loss: 0.7077 - val_accuracy: 0.5714 - val_loss: 0.6868\n",
      "Epoch 27/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5644 - loss: 0.6931 - val_accuracy: 0.5374 - val_loss: 0.6910\n",
      "Epoch 28/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5690 - loss: 0.7004 - val_accuracy: 0.5374 - val_loss: 0.6902\n",
      "Epoch 29/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5840 - loss: 0.6889 - val_accuracy: 0.5374 - val_loss: 0.6868\n",
      "Epoch 30/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5201 - loss: 0.7115 - val_accuracy: 0.5374 - val_loss: 0.6934\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.4929 - loss: 0.7123 \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T15:01:00.171251Z",
     "start_time": "2024-04-20T15:00:56.598623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Conv1D, Flatten\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, 1, activation='relu', input_shape=(1, 2)),  # Use kernel size of 1\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
    "cnn_performance = cnn_model.evaluate(X_test, y_test)"
   ],
   "id": "6ca4aac1efa555d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashl\\PycharmProjects\\MALWARE2024\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.4479 - loss: 7.4836 - val_accuracy: 0.5374 - val_loss: 2.0721\n",
      "Epoch 2/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5670 - loss: 1.1524 - val_accuracy: 0.5374 - val_loss: 0.9920\n",
      "Epoch 3/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5599 - loss: 0.8910 - val_accuracy: 0.5374 - val_loss: 0.7510\n",
      "Epoch 4/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5697 - loss: 0.7050 - val_accuracy: 0.5374 - val_loss: 0.6964\n",
      "Epoch 5/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5732 - loss: 0.6946 - val_accuracy: 0.4626 - val_loss: 0.7259\n",
      "Epoch 6/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5112 - loss: 0.7046 - val_accuracy: 0.5374 - val_loss: 0.7369\n",
      "Epoch 7/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5682 - loss: 0.6877 - val_accuracy: 0.5374 - val_loss: 0.6884\n",
      "Epoch 8/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5161 - loss: 0.7017 - val_accuracy: 0.5374 - val_loss: 0.7020\n",
      "Epoch 9/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5684 - loss: 0.6896 - val_accuracy: 0.5374 - val_loss: 0.7061\n",
      "Epoch 10/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5709 - loss: 0.6809 - val_accuracy: 0.5374 - val_loss: 0.7299\n",
      "Epoch 11/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5994 - loss: 0.6783 - val_accuracy: 0.4762 - val_loss: 0.7044\n",
      "Epoch 12/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5376 - loss: 0.6983 - val_accuracy: 0.5374 - val_loss: 0.7030\n",
      "Epoch 13/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5640 - loss: 0.7028 - val_accuracy: 0.5374 - val_loss: 0.6895\n",
      "Epoch 14/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5747 - loss: 0.6810 - val_accuracy: 0.4286 - val_loss: 0.6972\n",
      "Epoch 15/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5188 - loss: 0.7037 - val_accuracy: 0.5374 - val_loss: 0.7058\n",
      "Epoch 16/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5046 - loss: 0.7675 - val_accuracy: 0.5374 - val_loss: 0.7311\n",
      "Epoch 17/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.5360 - loss: 0.7117 - val_accuracy: 0.5374 - val_loss: 0.6909\n",
      "Epoch 18/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5700 - loss: 0.6921 - val_accuracy: 0.5374 - val_loss: 0.6902\n",
      "Epoch 19/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5378 - loss: 0.7280 - val_accuracy: 0.5374 - val_loss: 0.7874\n",
      "Epoch 20/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5405 - loss: 0.7792 - val_accuracy: 0.4694 - val_loss: 0.7218\n",
      "Epoch 21/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5278 - loss: 0.7151 - val_accuracy: 0.4626 - val_loss: 0.7051\n",
      "Epoch 22/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5395 - loss: 0.6920 - val_accuracy: 0.5374 - val_loss: 0.7612\n",
      "Epoch 23/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5440 - loss: 0.7205 - val_accuracy: 0.5374 - val_loss: 0.6985\n",
      "Epoch 24/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5913 - loss: 0.6737 - val_accuracy: 0.5374 - val_loss: 0.6960\n",
      "Epoch 25/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5428 - loss: 0.6971 - val_accuracy: 0.5374 - val_loss: 0.7186\n",
      "Epoch 26/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5603 - loss: 0.6941 - val_accuracy: 0.5374 - val_loss: 0.7158\n",
      "Epoch 27/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5517 - loss: 0.7229 - val_accuracy: 0.4762 - val_loss: 0.7057\n",
      "Epoch 28/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5680 - loss: 0.6845 - val_accuracy: 0.5374 - val_loss: 0.6925\n",
      "Epoch 29/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5325 - loss: 0.7021 - val_accuracy: 0.5374 - val_loss: 0.7086\n",
      "Epoch 30/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5662 - loss: 0.6998 - val_accuracy: 0.4490 - val_loss: 0.6938\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4604 - loss: 0.6940 \n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T15:01:01.142310Z",
     "start_time": "2024-04-20T15:01:00.173262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_probs = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_probs, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_probs, multi_class='ovr')\n",
    "    \n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "lstm_metrics = evaluate_model(lstm_model, X_test, y_test)\n",
    "gru_metrics = evaluate_model(gru_model, X_test, y_test)\n",
    "cnn_metrics = evaluate_model(cnn_model, X_test, y_test)\n",
    "\n",
    "models = ['LSTM', 'GRU', 'CNN']\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC']\n",
    "results = pd.DataFrame([lstm_metrics, gru_metrics, cnn_metrics], columns=metrics, index=models)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "results.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xticklabels(models, rotation=0)\n",
    "plt.show()\n",
    "\n",
    "results"
   ],
   "id": "f035b47b83590ac3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001ACBD8B34C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001B[1m1/5\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 49ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001ACBD8B34C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "      Accuracy  Precision   Recall  F1 Score   ROC-AUC\n",
       "LSTM  0.537415   0.537415  1.00000  0.699115  0.566456\n",
       "GRU   0.537415   0.537415  1.00000  0.699115  0.519173\n",
       "CNN   0.448980   0.490385  0.64557  0.557377  0.457930"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>0.537415</td>\n",
       "      <td>0.537415</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>0.566456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>0.537415</td>\n",
       "      <td>0.537415</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>0.519173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.490385</td>\n",
       "      <td>0.64557</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.457930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T15:01:06.696253Z",
     "start_time": "2024-04-20T15:01:01.144318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, 1, activation='relu', input_shape=(1, 2)),\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test)) \n",
    "cnn_performance = cnn_model.evaluate(X_test, y_test)"
   ],
   "id": "2e051a3ffc563163",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashl\\PycharmProjects\\MALWARE2024\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5177 - loss: 1.3113 - val_accuracy: 0.4626 - val_loss: 0.6972\n",
      "Epoch 2/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5324 - loss: 0.7104 - val_accuracy: 0.5374 - val_loss: 0.7421\n",
      "Epoch 3/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5268 - loss: 0.7212 - val_accuracy: 0.4830 - val_loss: 0.6939\n",
      "Epoch 4/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5131 - loss: 0.7939 - val_accuracy: 0.4626 - val_loss: 0.7410\n",
      "Epoch 5/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5072 - loss: 0.8502 - val_accuracy: 0.4694 - val_loss: 0.7569\n",
      "Epoch 6/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5074 - loss: 0.8338 - val_accuracy: 0.4490 - val_loss: 0.7233\n",
      "Epoch 7/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5059 - loss: 0.7807 - val_accuracy: 0.4898 - val_loss: 1.0343\n",
      "Epoch 8/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5339 - loss: 0.7537 - val_accuracy: 0.5374 - val_loss: 0.7685\n",
      "Epoch 9/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5102 - loss: 0.7893 - val_accuracy: 0.5374 - val_loss: 0.7068\n",
      "Epoch 10/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5889 - loss: 0.6778 - val_accuracy: 0.5374 - val_loss: 0.6899\n",
      "Epoch 11/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5478 - loss: 0.7218 - val_accuracy: 0.4830 - val_loss: 0.7084\n",
      "Epoch 12/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5727 - loss: 0.6989 - val_accuracy: 0.4762 - val_loss: 0.8434\n",
      "Epoch 13/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4859 - loss: 0.7876 - val_accuracy: 0.5374 - val_loss: 0.7141\n",
      "Epoch 14/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5872 - loss: 0.7028 - val_accuracy: 0.4490 - val_loss: 0.7349\n",
      "Epoch 15/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5448 - loss: 0.7582 - val_accuracy: 0.5374 - val_loss: 0.7073\n",
      "Epoch 16/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5444 - loss: 0.7843 - val_accuracy: 0.4694 - val_loss: 0.9629\n",
      "Epoch 17/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5521 - loss: 0.8084 - val_accuracy: 0.4218 - val_loss: 0.6963\n",
      "Epoch 18/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5037 - loss: 0.7909 - val_accuracy: 0.5374 - val_loss: 1.1531\n",
      "Epoch 19/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5439 - loss: 0.8972 - val_accuracy: 0.4762 - val_loss: 0.6943\n",
      "Epoch 20/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5136 - loss: 0.7289 - val_accuracy: 0.5374 - val_loss: 0.7666\n",
      "Epoch 21/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5522 - loss: 0.6975 - val_accuracy: 0.4490 - val_loss: 0.7006\n",
      "Epoch 22/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5409 - loss: 0.7217 - val_accuracy: 0.4830 - val_loss: 0.7090\n",
      "Epoch 23/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5509 - loss: 0.6844 - val_accuracy: 0.4558 - val_loss: 0.6986\n",
      "Epoch 24/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4978 - loss: 0.7176 - val_accuracy: 0.4762 - val_loss: 0.7185\n",
      "Epoch 25/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5228 - loss: 0.6996 - val_accuracy: 0.5374 - val_loss: 0.8369\n",
      "Epoch 26/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5437 - loss: 0.7365 - val_accuracy: 0.5374 - val_loss: 0.6897\n",
      "Epoch 27/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5501 - loss: 0.7154 - val_accuracy: 0.5374 - val_loss: 0.7459\n",
      "Epoch 28/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5620 - loss: 0.6968 - val_accuracy: 0.4626 - val_loss: 0.7350\n",
      "Epoch 29/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5277 - loss: 0.7147 - val_accuracy: 0.5374 - val_loss: 0.6889\n",
      "Epoch 30/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5548 - loss: 0.7030 - val_accuracy: 0.4558 - val_loss: 0.7020\n",
      "Epoch 31/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5257 - loss: 0.6969 - val_accuracy: 0.4626 - val_loss: 0.7037\n",
      "Epoch 32/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5511 - loss: 0.6955 - val_accuracy: 0.5374 - val_loss: 0.7081\n",
      "Epoch 33/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5181 - loss: 0.7213 - val_accuracy: 0.5374 - val_loss: 0.7538\n",
      "Epoch 34/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5216 - loss: 0.7333 - val_accuracy: 0.4762 - val_loss: 0.7046\n",
      "Epoch 35/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5586 - loss: 0.6870 - val_accuracy: 0.5374 - val_loss: 0.6889\n",
      "Epoch 36/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5148 - loss: 0.7009 - val_accuracy: 0.5374 - val_loss: 0.7426\n",
      "Epoch 37/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5182 - loss: 0.7394 - val_accuracy: 0.4694 - val_loss: 0.8342\n",
      "Epoch 38/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5387 - loss: 0.7157 - val_accuracy: 0.5374 - val_loss: 0.8080\n",
      "Epoch 39/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5494 - loss: 0.7165 - val_accuracy: 0.5374 - val_loss: 0.7360\n",
      "Epoch 40/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4916 - loss: 0.7326 - val_accuracy: 0.5374 - val_loss: 0.8011\n",
      "Epoch 41/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5143 - loss: 0.7357 - val_accuracy: 0.5374 - val_loss: 0.6866\n",
      "Epoch 42/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5331 - loss: 0.7199 - val_accuracy: 0.5374 - val_loss: 0.6960\n",
      "Epoch 43/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5375 - loss: 0.7213 - val_accuracy: 0.4898 - val_loss: 0.7092\n",
      "Epoch 44/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5283 - loss: 0.7628 - val_accuracy: 0.4490 - val_loss: 0.7320\n",
      "Epoch 45/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5385 - loss: 0.7105 - val_accuracy: 0.5374 - val_loss: 0.6866\n",
      "Epoch 46/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5919 - loss: 0.6922 - val_accuracy: 0.5374 - val_loss: 0.7323\n",
      "Epoch 47/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6066 - loss: 0.6715 - val_accuracy: 0.4422 - val_loss: 0.7534\n",
      "Epoch 48/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5296 - loss: 0.7087 - val_accuracy: 0.5374 - val_loss: 0.6959\n",
      "Epoch 49/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5527 - loss: 0.6872 - val_accuracy: 0.4354 - val_loss: 0.6972\n",
      "Epoch 50/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5778 - loss: 0.7363 - val_accuracy: 0.4762 - val_loss: 0.6991\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5159 - loss: 0.6935 \n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T15:02:48.899945Z",
     "start_time": "2024-04-20T15:02:23.274309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, input_shape=(1, 2)),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "\n",
    "# GRU Model\n",
    "gru_model = Sequential([\n",
    "    GRU(50, input_shape=(1, 2)),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "gru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "gru_model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "\n",
    "# CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, 1, activation='relu', input_shape=(1, 2)),\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n"
   ],
   "id": "a5cc29d5fe34aa3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashl\\PycharmProjects\\MALWARE2024\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.5195 - loss: 0.7044 - val_accuracy: 0.5374 - val_loss: 0.7170\n",
      "Epoch 2/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5449 - loss: 0.7142 - val_accuracy: 0.5102 - val_loss: 0.6991\n",
      "Epoch 3/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5717 - loss: 0.6806 - val_accuracy: 0.5238 - val_loss: 0.6944\n",
      "Epoch 4/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5701 - loss: 0.6840 - val_accuracy: 0.5374 - val_loss: 0.6948\n",
      "Epoch 5/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5297 - loss: 0.7019 - val_accuracy: 0.5374 - val_loss: 0.6998\n",
      "Epoch 6/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5503 - loss: 0.6822 - val_accuracy: 0.5374 - val_loss: 0.6955\n",
      "Epoch 7/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5656 - loss: 0.6907 - val_accuracy: 0.5374 - val_loss: 0.6934\n",
      "Epoch 8/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5439 - loss: 0.6973 - val_accuracy: 0.5374 - val_loss: 0.7015\n",
      "Epoch 9/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5834 - loss: 0.6852 - val_accuracy: 0.5374 - val_loss: 0.6953\n",
      "Epoch 10/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5390 - loss: 0.7091 - val_accuracy: 0.5510 - val_loss: 0.6944\n",
      "Epoch 11/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5390 - loss: 0.6938 - val_accuracy: 0.5374 - val_loss: 0.6984\n",
      "Epoch 12/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5505 - loss: 0.6840 - val_accuracy: 0.5374 - val_loss: 0.6988\n",
      "Epoch 13/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5719 - loss: 0.6967 - val_accuracy: 0.5374 - val_loss: 0.6957\n",
      "Epoch 14/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5887 - loss: 0.6815 - val_accuracy: 0.5374 - val_loss: 0.6942\n",
      "Epoch 15/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5463 - loss: 0.6991 - val_accuracy: 0.5374 - val_loss: 0.6952\n",
      "Epoch 16/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5802 - loss: 0.6751 - val_accuracy: 0.5374 - val_loss: 0.6966\n",
      "Epoch 17/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5326 - loss: 0.7015 - val_accuracy: 0.5374 - val_loss: 0.6948\n",
      "Epoch 18/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5646 - loss: 0.6878 - val_accuracy: 0.5374 - val_loss: 0.6961\n",
      "Epoch 19/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5558 - loss: 0.6864 - val_accuracy: 0.5442 - val_loss: 0.6955\n",
      "Epoch 20/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5730 - loss: 0.6847 - val_accuracy: 0.5374 - val_loss: 0.6957\n",
      "Epoch 21/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5558 - loss: 0.6860 - val_accuracy: 0.5374 - val_loss: 0.6971\n",
      "Epoch 22/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5784 - loss: 0.6794 - val_accuracy: 0.5442 - val_loss: 0.6924\n",
      "Epoch 23/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5115 - loss: 0.6952 - val_accuracy: 0.5442 - val_loss: 0.6910\n",
      "Epoch 24/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5877 - loss: 0.6820 - val_accuracy: 0.5374 - val_loss: 0.6940\n",
      "Epoch 25/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5832 - loss: 0.6741 - val_accuracy: 0.5374 - val_loss: 0.6955\n",
      "Epoch 26/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5556 - loss: 0.6895 - val_accuracy: 0.5442 - val_loss: 0.6922\n",
      "Epoch 27/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5451 - loss: 0.6892 - val_accuracy: 0.5374 - val_loss: 0.6943\n",
      "Epoch 28/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5548 - loss: 0.6920 - val_accuracy: 0.5442 - val_loss: 0.6911\n",
      "Epoch 29/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5752 - loss: 0.6753 - val_accuracy: 0.5374 - val_loss: 0.6935\n",
      "Epoch 30/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5476 - loss: 0.6934 - val_accuracy: 0.5374 - val_loss: 0.6934\n",
      "Epoch 31/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5674 - loss: 0.6806 - val_accuracy: 0.5442 - val_loss: 0.6912\n",
      "Epoch 32/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5538 - loss: 0.6975 - val_accuracy: 0.5374 - val_loss: 0.6928\n",
      "Epoch 33/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5743 - loss: 0.6891 - val_accuracy: 0.5374 - val_loss: 0.6924\n",
      "Epoch 34/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5681 - loss: 0.6771 - val_accuracy: 0.5442 - val_loss: 0.6895\n",
      "Epoch 35/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6079 - loss: 0.6703 - val_accuracy: 0.5374 - val_loss: 0.6932\n",
      "Epoch 36/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5782 - loss: 0.6735 - val_accuracy: 0.5646 - val_loss: 0.6886\n",
      "Epoch 37/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6102 - loss: 0.6732 - val_accuracy: 0.5374 - val_loss: 0.6937\n",
      "Epoch 38/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6347 - loss: 0.6569 - val_accuracy: 0.5442 - val_loss: 0.6901\n",
      "Epoch 39/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5654 - loss: 0.6820 - val_accuracy: 0.5510 - val_loss: 0.6880\n",
      "Epoch 40/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5536 - loss: 0.6877 - val_accuracy: 0.5442 - val_loss: 0.6910\n",
      "Epoch 41/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6071 - loss: 0.6723 - val_accuracy: 0.5442 - val_loss: 0.6912\n",
      "Epoch 42/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5913 - loss: 0.6714 - val_accuracy: 0.5442 - val_loss: 0.6907\n",
      "Epoch 43/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6035 - loss: 0.6661 - val_accuracy: 0.5442 - val_loss: 0.6902\n",
      "Epoch 44/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5977 - loss: 0.6722 - val_accuracy: 0.5510 - val_loss: 0.6883\n",
      "Epoch 45/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6013 - loss: 0.6684 - val_accuracy: 0.5646 - val_loss: 0.6903\n",
      "Epoch 46/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5686 - loss: 0.6773 - val_accuracy: 0.5510 - val_loss: 0.6888\n",
      "Epoch 47/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5581 - loss: 0.6862 - val_accuracy: 0.5510 - val_loss: 0.6909\n",
      "Epoch 48/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5711 - loss: 0.6698 - val_accuracy: 0.5510 - val_loss: 0.6894\n",
      "Epoch 49/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5923 - loss: 0.6662 - val_accuracy: 0.5646 - val_loss: 0.6898\n",
      "Epoch 50/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5666 - loss: 0.6773 - val_accuracy: 0.5442 - val_loss: 0.6899\n",
      "Epoch 1/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.5479 - loss: 0.6952 - val_accuracy: 0.5374 - val_loss: 0.6987\n",
      "Epoch 2/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5186 - loss: 0.7118 - val_accuracy: 0.5714 - val_loss: 0.6870\n",
      "Epoch 3/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4975 - loss: 0.7378 - val_accuracy: 0.5374 - val_loss: 0.6960\n",
      "Epoch 4/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5882 - loss: 0.6841 - val_accuracy: 0.5374 - val_loss: 0.6913\n",
      "Epoch 5/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5522 - loss: 0.7016 - val_accuracy: 0.5442 - val_loss: 0.6892\n",
      "Epoch 6/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5192 - loss: 0.7170 - val_accuracy: 0.5374 - val_loss: 0.7005\n",
      "Epoch 7/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6105 - loss: 0.6867 - val_accuracy: 0.5442 - val_loss: 0.6903\n",
      "Epoch 8/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4951 - loss: 0.7011 - val_accuracy: 0.5374 - val_loss: 0.7002\n",
      "Epoch 9/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5138 - loss: 0.7075 - val_accuracy: 0.5374 - val_loss: 0.6927\n",
      "Epoch 10/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5522 - loss: 0.6998 - val_accuracy: 0.5374 - val_loss: 0.6923\n",
      "Epoch 11/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5454 - loss: 0.6926 - val_accuracy: 0.5374 - val_loss: 0.6958\n",
      "Epoch 12/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5492 - loss: 0.7101 - val_accuracy: 0.5442 - val_loss: 0.6892\n",
      "Epoch 13/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5110 - loss: 0.6950 - val_accuracy: 0.5374 - val_loss: 0.6993\n",
      "Epoch 14/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5461 - loss: 0.6878 - val_accuracy: 0.5442 - val_loss: 0.6891\n",
      "Epoch 15/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5752 - loss: 0.6830 - val_accuracy: 0.5374 - val_loss: 0.6903\n",
      "Epoch 16/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5343 - loss: 0.7062 - val_accuracy: 0.5374 - val_loss: 0.6946\n",
      "Epoch 17/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5430 - loss: 0.6971 - val_accuracy: 0.5374 - val_loss: 0.6949\n",
      "Epoch 18/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5636 - loss: 0.6951 - val_accuracy: 0.5374 - val_loss: 0.6915\n",
      "Epoch 19/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5340 - loss: 0.7100 - val_accuracy: 0.5374 - val_loss: 0.6941\n",
      "Epoch 20/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5884 - loss: 0.6904 - val_accuracy: 0.5442 - val_loss: 0.6915\n",
      "Epoch 21/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5727 - loss: 0.6824 - val_accuracy: 0.5374 - val_loss: 0.6972\n",
      "Epoch 22/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5825 - loss: 0.6827 - val_accuracy: 0.5510 - val_loss: 0.6896\n",
      "Epoch 23/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5963 - loss: 0.6762 - val_accuracy: 0.5442 - val_loss: 0.6929\n",
      "Epoch 24/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5750 - loss: 0.6833 - val_accuracy: 0.5374 - val_loss: 0.6910\n",
      "Epoch 25/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5689 - loss: 0.6781 - val_accuracy: 0.5510 - val_loss: 0.6894\n",
      "Epoch 26/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5476 - loss: 0.6836 - val_accuracy: 0.5374 - val_loss: 0.6935\n",
      "Epoch 27/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5960 - loss: 0.6732 - val_accuracy: 0.5442 - val_loss: 0.6933\n",
      "Epoch 28/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5960 - loss: 0.6859 - val_accuracy: 0.5510 - val_loss: 0.6895\n",
      "Epoch 29/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5694 - loss: 0.6823 - val_accuracy: 0.5442 - val_loss: 0.6936\n",
      "Epoch 30/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5775 - loss: 0.6761 - val_accuracy: 0.5714 - val_loss: 0.6859\n",
      "Epoch 31/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5679 - loss: 0.6764 - val_accuracy: 0.5442 - val_loss: 0.6893\n",
      "Epoch 32/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5564 - loss: 0.6869 - val_accuracy: 0.5374 - val_loss: 0.6970\n",
      "Epoch 33/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5428 - loss: 0.7020 - val_accuracy: 0.5578 - val_loss: 0.6942\n",
      "Epoch 34/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5800 - loss: 0.6843 - val_accuracy: 0.5646 - val_loss: 0.6895\n",
      "Epoch 35/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5682 - loss: 0.6851 - val_accuracy: 0.5442 - val_loss: 0.6897\n",
      "Epoch 36/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5593 - loss: 0.6748 - val_accuracy: 0.5646 - val_loss: 0.6887\n",
      "Epoch 37/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5315 - loss: 0.6944 - val_accuracy: 0.5442 - val_loss: 0.6940\n",
      "Epoch 38/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6047 - loss: 0.6768 - val_accuracy: 0.5646 - val_loss: 0.6894\n",
      "Epoch 39/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5503 - loss: 0.6810 - val_accuracy: 0.5442 - val_loss: 0.6953\n",
      "Epoch 40/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6216 - loss: 0.6716 - val_accuracy: 0.5646 - val_loss: 0.6873\n",
      "Epoch 41/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5607 - loss: 0.6885 - val_accuracy: 0.5510 - val_loss: 0.6899\n",
      "Epoch 42/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5763 - loss: 0.6763 - val_accuracy: 0.5646 - val_loss: 0.6880\n",
      "Epoch 43/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5675 - loss: 0.6773 - val_accuracy: 0.5510 - val_loss: 0.6890\n",
      "Epoch 44/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5372 - loss: 0.6902 - val_accuracy: 0.5442 - val_loss: 0.6903\n",
      "Epoch 45/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5893 - loss: 0.6770 - val_accuracy: 0.5442 - val_loss: 0.6896\n",
      "Epoch 46/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5551 - loss: 0.6846 - val_accuracy: 0.5646 - val_loss: 0.6877\n",
      "Epoch 47/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5518 - loss: 0.6846 - val_accuracy: 0.5442 - val_loss: 0.6915\n",
      "Epoch 48/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5754 - loss: 0.6764 - val_accuracy: 0.5646 - val_loss: 0.6885\n",
      "Epoch 49/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5750 - loss: 0.6780 - val_accuracy: 0.5646 - val_loss: 0.6894\n",
      "Epoch 50/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5572 - loss: 0.6834 - val_accuracy: 0.5442 - val_loss: 0.6913\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashl\\PycharmProjects\\MALWARE2024\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.5031 - loss: 1.6175 - val_accuracy: 0.5374 - val_loss: 0.7955\n",
      "Epoch 2/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5454 - loss: 0.8181 - val_accuracy: 0.5374 - val_loss: 0.6937\n",
      "Epoch 3/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5637 - loss: 0.7137 - val_accuracy: 0.5374 - val_loss: 0.7115\n",
      "Epoch 4/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5173 - loss: 0.7224 - val_accuracy: 0.5374 - val_loss: 0.6895\n",
      "Epoch 5/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5445 - loss: 0.8002 - val_accuracy: 0.5374 - val_loss: 0.7751\n",
      "Epoch 6/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5231 - loss: 0.7509 - val_accuracy: 0.5102 - val_loss: 0.6936\n",
      "Epoch 7/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5333 - loss: 0.8022 - val_accuracy: 0.4626 - val_loss: 0.7772\n",
      "Epoch 8/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4868 - loss: 0.7601 - val_accuracy: 0.4626 - val_loss: 0.7241\n",
      "Epoch 9/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5493 - loss: 0.6982 - val_accuracy: 0.5374 - val_loss: 0.6887\n",
      "Epoch 10/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5463 - loss: 0.7229 - val_accuracy: 0.4762 - val_loss: 0.7179\n",
      "Epoch 11/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4980 - loss: 0.7097 - val_accuracy: 0.5374 - val_loss: 0.7332\n",
      "Epoch 12/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5341 - loss: 0.7616 - val_accuracy: 0.5374 - val_loss: 0.7946\n",
      "Epoch 13/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5116 - loss: 0.7539 - val_accuracy: 0.5374 - val_loss: 0.6930\n",
      "Epoch 14/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5550 - loss: 0.6950 - val_accuracy: 0.4626 - val_loss: 0.8276\n",
      "Epoch 15/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5214 - loss: 0.7951 - val_accuracy: 0.5374 - val_loss: 0.7182\n",
      "Epoch 16/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5481 - loss: 0.7211 - val_accuracy: 0.5374 - val_loss: 0.6922\n",
      "Epoch 17/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5680 - loss: 0.6987 - val_accuracy: 0.5374 - val_loss: 0.7598\n",
      "Epoch 18/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5186 - loss: 0.7599 - val_accuracy: 0.4422 - val_loss: 0.7014\n",
      "Epoch 19/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5669 - loss: 0.6978 - val_accuracy: 0.5374 - val_loss: 0.6928\n",
      "Epoch 20/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5696 - loss: 0.7111 - val_accuracy: 0.5374 - val_loss: 0.6887\n",
      "Epoch 21/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5781 - loss: 0.6986 - val_accuracy: 0.4626 - val_loss: 0.8142\n",
      "Epoch 22/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5426 - loss: 0.7251 - val_accuracy: 0.5374 - val_loss: 0.6910\n",
      "Epoch 23/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5064 - loss: 1.0202 - val_accuracy: 0.5374 - val_loss: 0.7686\n",
      "Epoch 24/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5547 - loss: 0.7126 - val_accuracy: 0.5374 - val_loss: 0.7784\n",
      "Epoch 25/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5677 - loss: 0.7268 - val_accuracy: 0.4490 - val_loss: 0.7357\n",
      "Epoch 26/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4914 - loss: 0.7782 - val_accuracy: 0.5374 - val_loss: 0.6875\n",
      "Epoch 27/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5625 - loss: 0.6984 - val_accuracy: 0.4490 - val_loss: 0.7406\n",
      "Epoch 28/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5110 - loss: 0.7715 - val_accuracy: 0.5374 - val_loss: 0.7363\n",
      "Epoch 29/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5777 - loss: 0.7048 - val_accuracy: 0.5374 - val_loss: 0.6877\n",
      "Epoch 30/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5243 - loss: 0.7015 - val_accuracy: 0.5374 - val_loss: 0.6872\n",
      "Epoch 31/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5790 - loss: 0.7286 - val_accuracy: 0.5374 - val_loss: 0.8101\n",
      "Epoch 32/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5146 - loss: 0.7364 - val_accuracy: 0.5238 - val_loss: 0.6901\n",
      "Epoch 33/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5452 - loss: 0.7158 - val_accuracy: 0.4490 - val_loss: 0.7289\n",
      "Epoch 34/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4606 - loss: 0.7531 - val_accuracy: 0.4762 - val_loss: 0.9282\n",
      "Epoch 35/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5281 - loss: 0.7801 - val_accuracy: 0.5374 - val_loss: 0.6900\n",
      "Epoch 36/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4944 - loss: 0.7203 - val_accuracy: 0.4558 - val_loss: 0.7241\n",
      "Epoch 37/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5298 - loss: 0.7095 - val_accuracy: 0.5374 - val_loss: 0.7212\n",
      "Epoch 38/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5901 - loss: 0.7234 - val_accuracy: 0.5374 - val_loss: 0.6901\n",
      "Epoch 39/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5238 - loss: 0.7214 - val_accuracy: 0.4762 - val_loss: 0.9031\n",
      "Epoch 40/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4668 - loss: 0.7995 - val_accuracy: 0.5374 - val_loss: 1.0202\n",
      "Epoch 41/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5315 - loss: 0.8524 - val_accuracy: 0.4626 - val_loss: 0.7150\n",
      "Epoch 42/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4980 - loss: 0.7201 - val_accuracy: 0.5374 - val_loss: 0.7748\n",
      "Epoch 43/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5724 - loss: 0.6951 - val_accuracy: 0.5374 - val_loss: 0.6850\n",
      "Epoch 44/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5950 - loss: 0.6912 - val_accuracy: 0.5374 - val_loss: 0.7357\n",
      "Epoch 45/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5262 - loss: 0.7372 - val_accuracy: 0.5374 - val_loss: 0.6866\n",
      "Epoch 46/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5584 - loss: 0.6839 - val_accuracy: 0.5374 - val_loss: 0.7252\n",
      "Epoch 47/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5195 - loss: 0.7147 - val_accuracy: 0.5374 - val_loss: 0.6838\n",
      "Epoch 48/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5795 - loss: 0.6790 - val_accuracy: 0.4422 - val_loss: 0.6926\n",
      "Epoch 49/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5317 - loss: 0.6982 - val_accuracy: 0.5374 - val_loss: 0.6901\n",
      "Epoch 50/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5872 - loss: 0.6768 - val_accuracy: 0.4286 - val_loss: 0.6939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1accd293ef0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T15:05:06.356428Z",
     "start_time": "2024-04-20T15:05:06.351501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from IPython.display import display, HTML\n",
    "import datetime\n",
    "\n",
    "# Set the base directory for saving logs\n",
    "base_log_path = \"tensorboard_logs/\"\n",
    "\n",
    "# Timestamp or a unique identifier for different training sessions\n",
    "log_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# TensorBoard callback setups\n",
    "tensorboard_callback_lstm = TensorBoard(log_dir=base_log_path + \"lstm/\" + log_time, histogram_freq=1)\n",
    "tensorboard_callback_gru = TensorBoard(log_dir=base_log_path + \"gru/\" + log_time, histogram_freq=1)\n",
    "tensorboard_callback_cnn = TensorBoard(log_dir=base_log_path + \"cnn/\" + log_time, histogram_freq=1)\n",
    "\n"
   ],
   "id": "5706e4bb33437127",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T15:05:33.797484Z",
     "start_time": "2024-04-20T15:05:12.346773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example for LSTM\n",
    "lstm_model.fit(X_train, y_train, epochs=50, batch_size=16,\n",
    "               validation_data=(X_test, y_test),\n",
    "               callbacks=[tensorboard_callback_lstm])\n",
    "\n",
    "# Example for GRU\n",
    "gru_model.fit(X_train, y_train, epochs=50, batch_size=16,\n",
    "              validation_data=(X_test, y_test),\n",
    "              callbacks=[tensorboard_callback_gru])\n",
    "\n",
    "# Example for CNN\n",
    "cnn_model.fit(X_train, y_train, epochs=50, batch_size=16,\n",
    "              validation_data=(X_test, y_test),\n",
    "              callbacks=[tensorboard_callback_cnn])\n"
   ],
   "id": "88b2f672a33a0aaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5696 - loss: 0.6804 - val_accuracy: 0.5714 - val_loss: 0.6875\n",
      "Epoch 2/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5731 - loss: 0.6886 - val_accuracy: 0.5510 - val_loss: 0.6911\n",
      "Epoch 3/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5887 - loss: 0.6816 - val_accuracy: 0.5442 - val_loss: 0.6913\n",
      "Epoch 4/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5591 - loss: 0.6833 - val_accuracy: 0.5442 - val_loss: 0.6918\n",
      "Epoch 5/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5756 - loss: 0.6788 - val_accuracy: 0.5646 - val_loss: 0.6886\n",
      "Epoch 6/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5793 - loss: 0.6730 - val_accuracy: 0.5510 - val_loss: 0.6896\n",
      "Epoch 7/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6188 - loss: 0.6663 - val_accuracy: 0.5646 - val_loss: 0.6882\n",
      "Epoch 8/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5719 - loss: 0.6753 - val_accuracy: 0.5510 - val_loss: 0.6883\n",
      "Epoch 9/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5861 - loss: 0.6743 - val_accuracy: 0.5510 - val_loss: 0.6862\n",
      "Epoch 10/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5618 - loss: 0.6831 - val_accuracy: 0.5510 - val_loss: 0.6883\n",
      "Epoch 11/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5652 - loss: 0.6799 - val_accuracy: 0.5646 - val_loss: 0.6899\n",
      "Epoch 12/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5900 - loss: 0.6750 - val_accuracy: 0.5646 - val_loss: 0.6914\n",
      "Epoch 13/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5474 - loss: 0.6920 - val_accuracy: 0.5646 - val_loss: 0.6887\n",
      "Epoch 14/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5795 - loss: 0.6749 - val_accuracy: 0.5510 - val_loss: 0.6898\n",
      "Epoch 15/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6050 - loss: 0.6682 - val_accuracy: 0.5714 - val_loss: 0.6874\n",
      "Epoch 16/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5646 - loss: 0.6816 - val_accuracy: 0.5646 - val_loss: 0.6898\n",
      "Epoch 17/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5666 - loss: 0.6757 - val_accuracy: 0.5646 - val_loss: 0.6894\n",
      "Epoch 18/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5760 - loss: 0.6858 - val_accuracy: 0.5578 - val_loss: 0.6918\n",
      "Epoch 19/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5952 - loss: 0.6783 - val_accuracy: 0.5646 - val_loss: 0.6898\n",
      "Epoch 20/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5752 - loss: 0.6766 - val_accuracy: 0.5510 - val_loss: 0.6898\n",
      "Epoch 21/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6014 - loss: 0.6692 - val_accuracy: 0.5646 - val_loss: 0.6885\n",
      "Epoch 22/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5952 - loss: 0.6761 - val_accuracy: 0.5646 - val_loss: 0.6895\n",
      "Epoch 23/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6040 - loss: 0.6756 - val_accuracy: 0.5646 - val_loss: 0.6890\n",
      "Epoch 24/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5575 - loss: 0.6806 - val_accuracy: 0.5646 - val_loss: 0.6887\n",
      "Epoch 25/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5869 - loss: 0.6710 - val_accuracy: 0.5646 - val_loss: 0.6890\n",
      "Epoch 26/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6288 - loss: 0.6642 - val_accuracy: 0.5714 - val_loss: 0.6864\n",
      "Epoch 27/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6063 - loss: 0.6671 - val_accuracy: 0.5646 - val_loss: 0.6891\n",
      "Epoch 28/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6065 - loss: 0.6614 - val_accuracy: 0.5510 - val_loss: 0.6886\n",
      "Epoch 29/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5834 - loss: 0.6747 - val_accuracy: 0.5714 - val_loss: 0.6866\n",
      "Epoch 30/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5458 - loss: 0.6875 - val_accuracy: 0.5646 - val_loss: 0.6906\n",
      "Epoch 31/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5676 - loss: 0.6815 - val_accuracy: 0.5442 - val_loss: 0.6927\n",
      "Epoch 32/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5819 - loss: 0.6745 - val_accuracy: 0.5646 - val_loss: 0.6899\n",
      "Epoch 33/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5958 - loss: 0.6654 - val_accuracy: 0.5646 - val_loss: 0.6907\n",
      "Epoch 34/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5706 - loss: 0.6801 - val_accuracy: 0.5714 - val_loss: 0.6887\n",
      "Epoch 35/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5663 - loss: 0.6855 - val_accuracy: 0.5646 - val_loss: 0.6887\n",
      "Epoch 36/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5900 - loss: 0.6731 - val_accuracy: 0.5646 - val_loss: 0.6884\n",
      "Epoch 37/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5729 - loss: 0.6763 - val_accuracy: 0.5714 - val_loss: 0.6855\n",
      "Epoch 38/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5903 - loss: 0.6722 - val_accuracy: 0.5442 - val_loss: 0.6921\n",
      "Epoch 39/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5852 - loss: 0.6724 - val_accuracy: 0.5646 - val_loss: 0.6893\n",
      "Epoch 40/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5844 - loss: 0.6703 - val_accuracy: 0.5646 - val_loss: 0.6884\n",
      "Epoch 41/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5623 - loss: 0.6771 - val_accuracy: 0.5646 - val_loss: 0.6887\n",
      "Epoch 42/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5784 - loss: 0.6786 - val_accuracy: 0.5646 - val_loss: 0.6880\n",
      "Epoch 43/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5853 - loss: 0.6730 - val_accuracy: 0.5714 - val_loss: 0.6882\n",
      "Epoch 44/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6047 - loss: 0.6612 - val_accuracy: 0.5714 - val_loss: 0.6848\n",
      "Epoch 45/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6223 - loss: 0.6673 - val_accuracy: 0.5714 - val_loss: 0.6845\n",
      "Epoch 46/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5907 - loss: 0.6670 - val_accuracy: 0.5646 - val_loss: 0.6878\n",
      "Epoch 47/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5941 - loss: 0.6719 - val_accuracy: 0.5646 - val_loss: 0.6906\n",
      "Epoch 48/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5868 - loss: 0.6774 - val_accuracy: 0.5714 - val_loss: 0.6850\n",
      "Epoch 49/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5765 - loss: 0.6744 - val_accuracy: 0.5510 - val_loss: 0.6892\n",
      "Epoch 50/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5912 - loss: 0.6703 - val_accuracy: 0.5646 - val_loss: 0.6875\n",
      "Epoch 1/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6085 - loss: 0.6695 - val_accuracy: 0.5646 - val_loss: 0.6887\n",
      "Epoch 2/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5704 - loss: 0.6805 - val_accuracy: 0.5442 - val_loss: 0.6925\n",
      "Epoch 3/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5534 - loss: 0.6767 - val_accuracy: 0.5646 - val_loss: 0.6899\n",
      "Epoch 4/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5850 - loss: 0.6799 - val_accuracy: 0.5646 - val_loss: 0.6879\n",
      "Epoch 5/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5665 - loss: 0.6795 - val_accuracy: 0.5442 - val_loss: 0.6899\n",
      "Epoch 6/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5755 - loss: 0.6755 - val_accuracy: 0.5510 - val_loss: 0.6903\n",
      "Epoch 7/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5540 - loss: 0.6839 - val_accuracy: 0.5646 - val_loss: 0.6897\n",
      "Epoch 8/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5848 - loss: 0.6779 - val_accuracy: 0.5646 - val_loss: 0.6886\n",
      "Epoch 9/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5590 - loss: 0.6806 - val_accuracy: 0.5646 - val_loss: 0.6890\n",
      "Epoch 10/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5685 - loss: 0.6728 - val_accuracy: 0.5646 - val_loss: 0.6877\n",
      "Epoch 11/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5774 - loss: 0.6751 - val_accuracy: 0.5646 - val_loss: 0.6869\n",
      "Epoch 12/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6014 - loss: 0.6731 - val_accuracy: 0.5646 - val_loss: 0.6896\n",
      "Epoch 13/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5902 - loss: 0.6663 - val_accuracy: 0.5646 - val_loss: 0.6887\n",
      "Epoch 14/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5941 - loss: 0.6774 - val_accuracy: 0.5646 - val_loss: 0.6894\n",
      "Epoch 15/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5792 - loss: 0.6807 - val_accuracy: 0.5646 - val_loss: 0.6899\n",
      "Epoch 16/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5823 - loss: 0.6720 - val_accuracy: 0.5646 - val_loss: 0.6907\n",
      "Epoch 17/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5979 - loss: 0.6729 - val_accuracy: 0.5714 - val_loss: 0.6849\n",
      "Epoch 18/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5746 - loss: 0.6763 - val_accuracy: 0.5578 - val_loss: 0.6899\n",
      "Epoch 19/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5588 - loss: 0.6831 - val_accuracy: 0.5442 - val_loss: 0.6924\n",
      "Epoch 20/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5840 - loss: 0.6706 - val_accuracy: 0.5646 - val_loss: 0.6877\n",
      "Epoch 21/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6050 - loss: 0.6714 - val_accuracy: 0.5646 - val_loss: 0.6889\n",
      "Epoch 22/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6008 - loss: 0.6696 - val_accuracy: 0.5646 - val_loss: 0.6851\n",
      "Epoch 23/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5556 - loss: 0.6818 - val_accuracy: 0.5578 - val_loss: 0.6903\n",
      "Epoch 24/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5830 - loss: 0.6720 - val_accuracy: 0.5442 - val_loss: 0.6894\n",
      "Epoch 25/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6011 - loss: 0.6702 - val_accuracy: 0.5646 - val_loss: 0.6869\n",
      "Epoch 26/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5925 - loss: 0.6694 - val_accuracy: 0.5646 - val_loss: 0.6879\n",
      "Epoch 27/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5784 - loss: 0.6801 - val_accuracy: 0.5646 - val_loss: 0.6893\n",
      "Epoch 28/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5726 - loss: 0.6789 - val_accuracy: 0.5646 - val_loss: 0.6891\n",
      "Epoch 29/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5669 - loss: 0.6845 - val_accuracy: 0.5578 - val_loss: 0.6937\n",
      "Epoch 30/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5657 - loss: 0.6794 - val_accuracy: 0.5646 - val_loss: 0.6865\n",
      "Epoch 31/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5682 - loss: 0.6826 - val_accuracy: 0.5646 - val_loss: 0.6869\n",
      "Epoch 32/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5990 - loss: 0.6686 - val_accuracy: 0.5646 - val_loss: 0.6863\n",
      "Epoch 33/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5666 - loss: 0.6854 - val_accuracy: 0.5646 - val_loss: 0.6879\n",
      "Epoch 34/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5907 - loss: 0.6743 - val_accuracy: 0.5714 - val_loss: 0.6859\n",
      "Epoch 35/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5735 - loss: 0.6723 - val_accuracy: 0.5646 - val_loss: 0.6891\n",
      "Epoch 36/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5479 - loss: 0.6850 - val_accuracy: 0.5646 - val_loss: 0.6911\n",
      "Epoch 37/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5822 - loss: 0.6742 - val_accuracy: 0.5646 - val_loss: 0.6868\n",
      "Epoch 38/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5644 - loss: 0.6752 - val_accuracy: 0.5646 - val_loss: 0.6873\n",
      "Epoch 39/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6316 - loss: 0.6570 - val_accuracy: 0.5646 - val_loss: 0.6878\n",
      "Epoch 40/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6103 - loss: 0.6679 - val_accuracy: 0.5714 - val_loss: 0.6859\n",
      "Epoch 41/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6104 - loss: 0.6667 - val_accuracy: 0.5646 - val_loss: 0.6855\n",
      "Epoch 42/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5761 - loss: 0.6758 - val_accuracy: 0.5646 - val_loss: 0.6866\n",
      "Epoch 43/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5825 - loss: 0.6772 - val_accuracy: 0.5578 - val_loss: 0.6896\n",
      "Epoch 44/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5894 - loss: 0.6681 - val_accuracy: 0.5646 - val_loss: 0.6879\n",
      "Epoch 45/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5690 - loss: 0.6731 - val_accuracy: 0.5646 - val_loss: 0.6908\n",
      "Epoch 46/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5704 - loss: 0.6808 - val_accuracy: 0.5646 - val_loss: 0.6878\n",
      "Epoch 47/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5820 - loss: 0.6760 - val_accuracy: 0.5578 - val_loss: 0.6898\n",
      "Epoch 48/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5759 - loss: 0.6769 - val_accuracy: 0.5646 - val_loss: 0.6872\n",
      "Epoch 49/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6401 - loss: 0.6534 - val_accuracy: 0.5646 - val_loss: 0.6849\n",
      "Epoch 50/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5669 - loss: 0.6792 - val_accuracy: 0.5646 - val_loss: 0.6883\n",
      "Epoch 1/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5279 - loss: 0.7051 - val_accuracy: 0.5374 - val_loss: 0.6869\n",
      "Epoch 2/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5704 - loss: 0.6810 - val_accuracy: 0.4966 - val_loss: 0.7018\n",
      "Epoch 3/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5694 - loss: 0.6834 - val_accuracy: 0.4694 - val_loss: 0.7105\n",
      "Epoch 4/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5804 - loss: 0.6905 - val_accuracy: 0.4694 - val_loss: 0.7862\n",
      "Epoch 5/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5092 - loss: 0.7295 - val_accuracy: 0.5374 - val_loss: 0.7092\n",
      "Epoch 6/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6052 - loss: 0.6736 - val_accuracy: 0.4558 - val_loss: 0.7559\n",
      "Epoch 7/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4899 - loss: 0.8019 - val_accuracy: 0.4626 - val_loss: 0.7463\n",
      "Epoch 8/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5352 - loss: 0.7058 - val_accuracy: 0.5374 - val_loss: 0.7230\n",
      "Epoch 9/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5442 - loss: 0.7008 - val_accuracy: 0.4286 - val_loss: 0.6936\n",
      "Epoch 10/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4819 - loss: 0.7455 - val_accuracy: 0.5374 - val_loss: 0.6919\n",
      "Epoch 11/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5550 - loss: 0.6834 - val_accuracy: 0.4626 - val_loss: 0.7084\n",
      "Epoch 12/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5683 - loss: 0.6793 - val_accuracy: 0.4762 - val_loss: 0.7054\n",
      "Epoch 13/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5514 - loss: 0.6985 - val_accuracy: 0.5374 - val_loss: 0.7342\n",
      "Epoch 14/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5797 - loss: 0.6841 - val_accuracy: 0.4762 - val_loss: 0.8098\n",
      "Epoch 15/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5619 - loss: 0.7215 - val_accuracy: 0.4490 - val_loss: 0.7145\n",
      "Epoch 16/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5276 - loss: 0.7418 - val_accuracy: 0.5374 - val_loss: 0.6824\n",
      "Epoch 17/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5651 - loss: 0.6860 - val_accuracy: 0.5374 - val_loss: 0.6824\n",
      "Epoch 18/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4900 - loss: 0.7074 - val_accuracy: 0.5374 - val_loss: 0.7616\n",
      "Epoch 19/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4903 - loss: 0.7229 - val_accuracy: 0.5374 - val_loss: 0.7052\n",
      "Epoch 20/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4767 - loss: 0.7203 - val_accuracy: 0.5374 - val_loss: 0.7583\n",
      "Epoch 21/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5446 - loss: 0.7199 - val_accuracy: 0.5374 - val_loss: 0.6863\n",
      "Epoch 22/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5042 - loss: 0.7049 - val_accuracy: 0.4762 - val_loss: 0.8517\n",
      "Epoch 23/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5237 - loss: 0.7629 - val_accuracy: 0.5374 - val_loss: 0.6970\n",
      "Epoch 24/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5500 - loss: 0.6782 - val_accuracy: 0.5374 - val_loss: 0.6870\n",
      "Epoch 25/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5582 - loss: 0.6945 - val_accuracy: 0.5374 - val_loss: 0.6965\n",
      "Epoch 26/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5484 - loss: 0.6919 - val_accuracy: 0.5374 - val_loss: 0.6841\n",
      "Epoch 27/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5618 - loss: 0.6822 - val_accuracy: 0.5374 - val_loss: 0.6850\n",
      "Epoch 28/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5845 - loss: 0.6729 - val_accuracy: 0.5374 - val_loss: 0.6862\n",
      "Epoch 29/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5727 - loss: 0.6834 - val_accuracy: 0.4490 - val_loss: 0.7243\n",
      "Epoch 30/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5173 - loss: 0.6955 - val_accuracy: 0.5374 - val_loss: 0.6848\n",
      "Epoch 31/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5557 - loss: 0.6854 - val_accuracy: 0.4558 - val_loss: 0.6875\n",
      "Epoch 32/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4803 - loss: 0.7256 - val_accuracy: 0.5374 - val_loss: 0.6848\n",
      "Epoch 33/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5234 - loss: 0.6844 - val_accuracy: 0.5102 - val_loss: 0.6958\n",
      "Epoch 34/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5613 - loss: 0.6867 - val_accuracy: 0.5374 - val_loss: 0.6825\n",
      "Epoch 35/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5609 - loss: 0.6809 - val_accuracy: 0.5374 - val_loss: 0.7145\n",
      "Epoch 36/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5049 - loss: 0.7364 - val_accuracy: 0.5374 - val_loss: 0.7078\n",
      "Epoch 37/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5839 - loss: 0.6895 - val_accuracy: 0.4558 - val_loss: 0.6915\n",
      "Epoch 38/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5213 - loss: 0.6904 - val_accuracy: 0.5374 - val_loss: 0.6841\n",
      "Epoch 39/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5916 - loss: 0.6748 - val_accuracy: 0.5034 - val_loss: 0.6990\n",
      "Epoch 40/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5762 - loss: 0.7023 - val_accuracy: 0.5374 - val_loss: 0.6833\n",
      "Epoch 41/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5654 - loss: 0.6794 - val_accuracy: 0.5374 - val_loss: 0.6853\n",
      "Epoch 42/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5684 - loss: 0.6888 - val_accuracy: 0.5374 - val_loss: 0.7613\n",
      "Epoch 43/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5806 - loss: 0.6657 - val_accuracy: 0.5374 - val_loss: 0.6826\n",
      "Epoch 44/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5337 - loss: 0.6887 - val_accuracy: 0.5034 - val_loss: 0.6986\n",
      "Epoch 45/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5385 - loss: 0.7230 - val_accuracy: 0.5374 - val_loss: 0.6865\n",
      "Epoch 46/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5195 - loss: 0.7120 - val_accuracy: 0.4966 - val_loss: 0.6981\n",
      "Epoch 47/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5377 - loss: 0.6850 - val_accuracy: 0.4490 - val_loss: 0.7209\n",
      "Epoch 48/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5266 - loss: 0.7002 - val_accuracy: 0.5374 - val_loss: 0.6848\n",
      "Epoch 49/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5416 - loss: 0.6945 - val_accuracy: 0.5374 - val_loss: 0.7151\n",
      "Epoch 50/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5227 - loss: 0.7214 - val_accuracy: 0.5374 - val_loss: 0.6831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1accfbcea80>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T15:06:02.846190Z",
     "start_time": "2024-04-20T15:06:02.837270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Start TensorBoard within the notebook using the same log directory as the callbacks\n",
    "%tensorboard --logdir tensorboard_logs/"
   ],
   "id": "78dab4248677cd85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 21264), started 0:00:21 ago. (Use '!kill 21264' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a647e6831e608def\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a647e6831e608def\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "204fa6a654570fb6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

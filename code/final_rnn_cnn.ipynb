{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Data Exploration and Preprocessing: Understand the structure of the dataset, preprocess it as needed, and prepare it for modeling.",
   "id": "a9a4e096820acdea"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-20T14:19:41.619105Z",
     "start_time": "2024-04-20T14:19:41.592780Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = '/Users/yashl/PycharmProjects/MALWARE2024/data/combined_data_ag.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data.head(), data.describe(), data.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 735 entries, 0 to 734\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Mnemonic   735 non-null    object\n",
      " 1   Frequency  735 non-null    int64 \n",
      " 2   Label      735 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 17.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  Mnemonic  Frequency  Label\n",
       " 0      out          2      1\n",
       " 1      jae         18      0\n",
       " 2      shl        110      1\n",
       " 3      and         26      0\n",
       " 4      jne          3      0,\n",
       "          Frequency       Label\n",
       " count   735.000000  735.000000\n",
       " mean    116.442177    0.570068\n",
       " std     524.899984    0.495403\n",
       " min       1.000000    0.000000\n",
       " 25%       1.000000    0.000000\n",
       " 50%       5.000000    1.000000\n",
       " 75%      37.500000    1.000000\n",
       " max    7501.000000    1.000000,\n",
       " None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T14:20:30.162700Z",
     "start_time": "2024-04-20T14:20:30.138807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "mnemonic_encoded = encoder.fit_transform(data[['Mnemonic']])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "frequency_scaled = scaler.fit_transform(data[['Frequency']])\n",
    "\n",
    "import numpy as np\n",
    "features = np.concatenate([mnemonic_encoded, frequency_scaled], axis=1)\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "features_df['Label'] = data['Label']\n",
    "\n",
    "features_df.head()"
   ],
   "id": "39c4b0a2345615b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  129  130  131  132  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   133  134  135  136       137  Label  \n",
       "0  0.0  0.0  0.0  0.0  0.000133      1  \n",
       "1  0.0  0.0  0.0  0.0  0.002267      0  \n",
       "2  0.0  0.0  0.0  0.0  0.014533      1  \n",
       "3  0.0  0.0  0.0  0.0  0.003333      0  \n",
       "4  0.0  0.0  0.0  0.0  0.000267      0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T14:20:43.123359Z",
     "start_time": "2024-04-20T14:20:42.155569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = features_df.drop('Label', axis=1)\n",
    "y = features_df['Label']\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "rfe = RFE(estimator=logreg, n_features_to_select=20)  # Let's select top 20 features for simplicity\n",
    "rfe.fit(X, y)\n",
    "selected_features = rfe.support_\n",
    "selected_feature_names = [f\"Feature_{i}\" for i in range(X.shape[1]) if selected_features[i]]\n",
    "\n",
    "selected_feature_names"
   ],
   "id": "8c758fa17ed2c686",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feature_0',\n",
       " 'Feature_4',\n",
       " 'Feature_7',\n",
       " 'Feature_12',\n",
       " 'Feature_13',\n",
       " 'Feature_15',\n",
       " 'Feature_16',\n",
       " 'Feature_17',\n",
       " 'Feature_29',\n",
       " 'Feature_31',\n",
       " 'Feature_44',\n",
       " 'Feature_46',\n",
       " 'Feature_64',\n",
       " 'Feature_72',\n",
       " 'Feature_81',\n",
       " 'Feature_87',\n",
       " 'Feature_90',\n",
       " 'Feature_110',\n",
       " 'Feature_126',\n",
       " 'Feature_137']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T14:25:51.264539Z",
     "start_time": "2024-04-20T14:25:51.252787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "label_encoder = LabelEncoder()\n",
    "data['Mnemonic_encoded'] = label_encoder.fit_transform(data['Mnemonic'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data['Frequency_scaled'] = scaler.fit_transform(data[['Frequency']])\n",
    "\n",
    "data.head()"
   ],
   "id": "c6c1c779ff78587",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Mnemonic  Frequency  Label  Mnemonic_encoded  Frequency_scaled\n",
       "0      out          2      1                92          0.000133\n",
       "1      jae         18      0                53          0.002267\n",
       "2      shl        110      1               123          0.014533\n",
       "3      and         26      0                 6          0.003333\n",
       "4      jne          3      0                62          0.000267"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mnemonic</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Label</th>\n",
       "      <th>Mnemonic_encoded</th>\n",
       "      <th>Frequency_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>out</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jae</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.002267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shl</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0.014533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jne</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T14:26:19.947722Z",
     "start_time": "2024-04-20T14:26:19.930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "rfe = RFE(estimator=logreg, n_features_to_select=1, step=1)\n",
    "rfe.fit(data[['Mnemonic_encoded', 'Frequency_scaled']], data['Label'])\n",
    "\n",
    "selected_features = pd.DataFrame({\n",
    "    'Feature': ['Mnemonic_encoded', 'Frequency_scaled'],\n",
    "    'Importance': rfe.ranking_\n",
    "})\n",
    "selected_features.sort_values(by='Importance')\n"
   ],
   "id": "1ad7d9f7e7a66c19",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Feature  Importance\n",
       "1  Frequency_scaled           1\n",
       "0  Mnemonic_encoded           2"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frequency_scaled</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mnemonic_encoded</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T14:26:32.934949Z",
     "start_time": "2024-04-20T14:26:32.804110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, GRU, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X = data[['Mnemonic_encoded', 'Frequency_scaled']].values.reshape(-1, 1, 2)\n",
    "y = to_categorical(data['Label'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, input_shape=(1, 2)),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.summary()"
   ],
   "id": "39c2f796c1309792",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashl\\PycharmProjects\\MALWARE2024\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │        \u001B[38;5;34m10,600\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m50\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m)              │           \u001B[38;5;34m102\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m10,702\u001B[0m (41.80 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,702</span> (41.80 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m10,702\u001B[0m (41.80 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,702</span> (41.80 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T14:27:31.890542Z",
     "start_time": "2024-04-20T14:27:27.780177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gru_model = Sequential([\n",
    "    GRU(50, input_shape=(1, 2)),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "gru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "gru_model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
    "gru_performance = gru_model.evaluate(X_test, y_test)"
   ],
   "id": "20bbf32f6aae4f1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashl\\PycharmProjects\\MALWARE2024\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.5047 - loss: 0.7327 - val_accuracy: 0.5374 - val_loss: 0.6973\n",
      "Epoch 2/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5746 - loss: 0.6949 - val_accuracy: 0.5374 - val_loss: 0.6965\n",
      "Epoch 3/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5339 - loss: 0.7247 - val_accuracy: 0.5374 - val_loss: 0.6900\n",
      "Epoch 4/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5708 - loss: 0.6981 - val_accuracy: 0.5374 - val_loss: 0.6962\n",
      "Epoch 5/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5663 - loss: 0.6927 - val_accuracy: 0.5374 - val_loss: 0.6932\n",
      "Epoch 6/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5359 - loss: 0.6982 - val_accuracy: 0.5374 - val_loss: 0.6936\n",
      "Epoch 7/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6268 - loss: 0.6595 - val_accuracy: 0.5374 - val_loss: 0.6968\n",
      "Epoch 8/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5394 - loss: 0.7025 - val_accuracy: 0.5374 - val_loss: 0.6955\n",
      "Epoch 9/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5268 - loss: 0.7061 - val_accuracy: 0.5374 - val_loss: 0.6906\n",
      "Epoch 10/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5522 - loss: 0.6951 - val_accuracy: 0.5374 - val_loss: 0.6928\n",
      "Epoch 11/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5443 - loss: 0.7144 - val_accuracy: 0.5374 - val_loss: 0.6957\n",
      "Epoch 12/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5321 - loss: 0.7111 - val_accuracy: 0.5374 - val_loss: 0.6920\n",
      "Epoch 13/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5451 - loss: 0.7190 - val_accuracy: 0.5374 - val_loss: 0.6979\n",
      "Epoch 14/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5734 - loss: 0.6990 - val_accuracy: 0.5374 - val_loss: 0.6941\n",
      "Epoch 15/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5741 - loss: 0.7022 - val_accuracy: 0.5374 - val_loss: 0.6946\n",
      "Epoch 16/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5605 - loss: 0.6986 - val_accuracy: 0.5374 - val_loss: 0.6959\n",
      "Epoch 17/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5618 - loss: 0.6921 - val_accuracy: 0.5374 - val_loss: 0.7027\n",
      "Epoch 18/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5710 - loss: 0.7023 - val_accuracy: 0.5442 - val_loss: 0.6969\n",
      "Epoch 19/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5774 - loss: 0.6697 - val_accuracy: 0.5578 - val_loss: 0.6950\n",
      "Epoch 20/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5837 - loss: 0.6820 - val_accuracy: 0.5442 - val_loss: 0.6941\n",
      "Epoch 21/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5218 - loss: 0.6976 - val_accuracy: 0.5374 - val_loss: 0.6964\n",
      "Epoch 22/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5880 - loss: 0.6735 - val_accuracy: 0.5442 - val_loss: 0.6971\n",
      "Epoch 23/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5546 - loss: 0.6965 - val_accuracy: 0.5374 - val_loss: 0.6972\n",
      "Epoch 24/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5175 - loss: 0.7093 - val_accuracy: 0.5374 - val_loss: 0.6976\n",
      "Epoch 25/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5674 - loss: 0.6868 - val_accuracy: 0.5578 - val_loss: 0.6998\n",
      "Epoch 26/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5958 - loss: 0.6877 - val_accuracy: 0.5714 - val_loss: 0.6910\n",
      "Epoch 27/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5586 - loss: 0.6838 - val_accuracy: 0.5442 - val_loss: 0.6989\n",
      "Epoch 28/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5804 - loss: 0.6734 - val_accuracy: 0.5442 - val_loss: 0.6933\n",
      "Epoch 29/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5515 - loss: 0.6836 - val_accuracy: 0.5442 - val_loss: 0.6958\n",
      "Epoch 30/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5741 - loss: 0.6874 - val_accuracy: 0.5442 - val_loss: 0.6950\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5009 - loss: 0.7057 \n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T14:28:59.359194Z",
     "start_time": "2024-04-20T14:28:56.141368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Conv1D, Flatten\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, 1, activation='relu', input_shape=(1, 2)),  # Use kernel size of 1\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
    "cnn_performance = cnn_model.evaluate(X_test, y_test)"
   ],
   "id": "6ca4aac1efa555d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashl\\PycharmProjects\\MALWARE2024\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.4843 - loss: 1.2131 - val_accuracy: 0.5374 - val_loss: 0.6869\n",
      "Epoch 2/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5063 - loss: 0.7565 - val_accuracy: 0.5374 - val_loss: 0.7140\n",
      "Epoch 3/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5870 - loss: 0.8350 - val_accuracy: 0.5374 - val_loss: 0.7979\n",
      "Epoch 4/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5701 - loss: 0.7907 - val_accuracy: 0.4694 - val_loss: 0.9709\n",
      "Epoch 5/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4680 - loss: 0.8439 - val_accuracy: 0.5374 - val_loss: 0.6867\n",
      "Epoch 6/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5137 - loss: 0.7447 - val_accuracy: 0.5374 - val_loss: 0.7330\n",
      "Epoch 7/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5782 - loss: 0.6961 - val_accuracy: 0.4626 - val_loss: 0.7021\n",
      "Epoch 8/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5047 - loss: 0.7013 - val_accuracy: 0.4898 - val_loss: 0.6978\n",
      "Epoch 9/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5297 - loss: 0.7157 - val_accuracy: 0.4694 - val_loss: 0.7035\n",
      "Epoch 10/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5218 - loss: 0.7237 - val_accuracy: 0.5374 - val_loss: 0.6923\n",
      "Epoch 11/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5310 - loss: 0.6941 - val_accuracy: 0.4626 - val_loss: 0.7094\n",
      "Epoch 12/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5432 - loss: 0.6935 - val_accuracy: 0.5374 - val_loss: 0.6877\n",
      "Epoch 13/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5292 - loss: 0.7560 - val_accuracy: 0.5374 - val_loss: 0.7446\n",
      "Epoch 14/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5265 - loss: 0.7418 - val_accuracy: 0.5374 - val_loss: 0.6909\n",
      "Epoch 15/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5738 - loss: 0.7183 - val_accuracy: 0.4762 - val_loss: 0.8666\n",
      "Epoch 16/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4961 - loss: 0.8778 - val_accuracy: 0.5374 - val_loss: 0.7728\n",
      "Epoch 17/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5301 - loss: 0.7372 - val_accuracy: 0.5374 - val_loss: 0.6878\n",
      "Epoch 18/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5160 - loss: 0.6980 - val_accuracy: 0.5374 - val_loss: 0.7143\n",
      "Epoch 19/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5636 - loss: 0.6902 - val_accuracy: 0.5374 - val_loss: 0.6975\n",
      "Epoch 20/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5862 - loss: 0.6836 - val_accuracy: 0.5374 - val_loss: 0.6879\n",
      "Epoch 21/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5261 - loss: 0.7131 - val_accuracy: 0.4694 - val_loss: 0.7844\n",
      "Epoch 22/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5323 - loss: 0.7016 - val_accuracy: 0.5374 - val_loss: 0.6874\n",
      "Epoch 23/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4509 - loss: 0.7442 - val_accuracy: 0.5374 - val_loss: 0.7337\n",
      "Epoch 24/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4874 - loss: 0.7866 - val_accuracy: 0.5374 - val_loss: 0.8015\n",
      "Epoch 25/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4925 - loss: 0.7623 - val_accuracy: 0.5374 - val_loss: 0.7417\n",
      "Epoch 26/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5510 - loss: 0.7069 - val_accuracy: 0.4286 - val_loss: 0.6981\n",
      "Epoch 27/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5521 - loss: 0.6918 - val_accuracy: 0.4626 - val_loss: 0.7218\n",
      "Epoch 28/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5071 - loss: 0.7241 - val_accuracy: 0.5374 - val_loss: 0.6970\n",
      "Epoch 29/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5755 - loss: 0.6886 - val_accuracy: 0.5374 - val_loss: 0.6919\n",
      "Epoch 30/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5209 - loss: 0.7469 - val_accuracy: 0.5374 - val_loss: 0.6941\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.4929 - loss: 0.7204 \n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T14:31:20.425174Z",
     "start_time": "2024-04-20T14:31:18.769139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_probs = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_probs, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_probs, multi_class='ovr')\n",
    "    \n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "lstm_metrics = evaluate_model(lstm_model, X_test, y_test)\n",
    "gru_metrics = evaluate_model(gru_model, X_test, y_test)\n",
    "cnn_metrics = evaluate_model(cnn_model, X_test, y_test)\n",
    "\n",
    "models = ['LSTM', 'GRU', 'CNN']\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC']\n",
    "results = pd.DataFrame([lstm_metrics, gru_metrics, cnn_metrics], columns=metrics, index=models)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "results.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xticklabels(models, rotation=0)\n",
    "plt.show()\n",
    "\n",
    "results"
   ],
   "id": "f035b47b83590ac3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 90ms/step\n",
      "\u001B[1m1/5\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 145ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashl\\PycharmProjects\\MALWARE2024\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000018AA5F105E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001B[1m1/5\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 48ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000018AA5F105E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "      Accuracy  Precision  Recall  F1 Score   ROC-AUC\n",
       "LSTM  0.462585   0.000000     0.0  0.000000  0.440060\n",
       "GRU   0.544218   0.541096     1.0  0.702222  0.490320\n",
       "CNN   0.537415   0.537415     1.0  0.699115  0.591586"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>0.462585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>0.544218</td>\n",
       "      <td>0.541096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.702222</td>\n",
       "      <td>0.490320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.537415</td>\n",
       "      <td>0.537415</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>0.591586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T14:41:06.936233Z",
     "start_time": "2024-04-20T14:41:01.476354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, 1, activation='relu', input_shape=(1, 2)),\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test)) \n",
    "cnn_performance = cnn_model.evaluate(X_test, y_test)"
   ],
   "id": "2e051a3ffc563163",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashl\\PycharmProjects\\MALWARE2024\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.4846 - loss: 4.5573 - val_accuracy: 0.5374 - val_loss: 1.1278\n",
      "Epoch 2/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4942 - loss: 0.9526 - val_accuracy: 0.4626 - val_loss: 0.7195\n",
      "Epoch 3/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4939 - loss: 0.7857 - val_accuracy: 0.5374 - val_loss: 0.7218\n",
      "Epoch 4/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5358 - loss: 0.7340 - val_accuracy: 0.4762 - val_loss: 0.7603\n",
      "Epoch 5/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5383 - loss: 0.7429 - val_accuracy: 0.5374 - val_loss: 0.8797\n",
      "Epoch 6/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5199 - loss: 0.7597 - val_accuracy: 0.5374 - val_loss: 0.7053\n",
      "Epoch 7/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5730 - loss: 0.6981 - val_accuracy: 0.5374 - val_loss: 0.7445\n",
      "Epoch 8/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5315 - loss: 0.7284 - val_accuracy: 0.4558 - val_loss: 0.7371\n",
      "Epoch 9/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5108 - loss: 0.7397 - val_accuracy: 0.5374 - val_loss: 0.6927\n",
      "Epoch 10/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5473 - loss: 0.7107 - val_accuracy: 0.4762 - val_loss: 0.7138\n",
      "Epoch 11/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4971 - loss: 0.7974 - val_accuracy: 0.5374 - val_loss: 0.6916\n",
      "Epoch 12/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5057 - loss: 0.7418 - val_accuracy: 0.5374 - val_loss: 0.7078\n",
      "Epoch 13/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5217 - loss: 0.7143 - val_accuracy: 0.4898 - val_loss: 0.7115\n",
      "Epoch 14/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5152 - loss: 0.7470 - val_accuracy: 0.5374 - val_loss: 0.7344\n",
      "Epoch 15/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5546 - loss: 0.7111 - val_accuracy: 0.5374 - val_loss: 0.7129\n",
      "Epoch 16/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5535 - loss: 0.7027 - val_accuracy: 0.4558 - val_loss: 0.7300\n",
      "Epoch 17/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5419 - loss: 0.7662 - val_accuracy: 0.5374 - val_loss: 0.7144\n",
      "Epoch 18/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5814 - loss: 0.7029 - val_accuracy: 0.5374 - val_loss: 0.6901\n",
      "Epoch 19/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5784 - loss: 0.7182 - val_accuracy: 0.4898 - val_loss: 0.7121\n",
      "Epoch 20/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5778 - loss: 0.7037 - val_accuracy: 0.4490 - val_loss: 0.7730\n",
      "Epoch 21/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5182 - loss: 0.7178 - val_accuracy: 0.5374 - val_loss: 0.6882\n",
      "Epoch 22/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5569 - loss: 0.7045 - val_accuracy: 0.4558 - val_loss: 0.7367\n",
      "Epoch 23/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5279 - loss: 0.6975 - val_accuracy: 0.5374 - val_loss: 0.6911\n",
      "Epoch 24/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5528 - loss: 0.7794 - val_accuracy: 0.5374 - val_loss: 0.6960\n",
      "Epoch 25/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5624 - loss: 0.8382 - val_accuracy: 0.5374 - val_loss: 0.6881\n",
      "Epoch 26/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5412 - loss: 0.7014 - val_accuracy: 0.5374 - val_loss: 0.6878\n",
      "Epoch 27/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5396 - loss: 0.6963 - val_accuracy: 0.4694 - val_loss: 0.7139\n",
      "Epoch 28/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5342 - loss: 0.6950 - val_accuracy: 0.5374 - val_loss: 0.6981\n",
      "Epoch 29/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5596 - loss: 0.6867 - val_accuracy: 0.5374 - val_loss: 0.7239\n",
      "Epoch 30/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5543 - loss: 0.7370 - val_accuracy: 0.5374 - val_loss: 0.7224\n",
      "Epoch 31/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5301 - loss: 0.7153 - val_accuracy: 0.5374 - val_loss: 0.8511\n",
      "Epoch 32/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4860 - loss: 0.9049 - val_accuracy: 0.5374 - val_loss: 0.6858\n",
      "Epoch 33/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5331 - loss: 0.7481 - val_accuracy: 0.4490 - val_loss: 0.7288\n",
      "Epoch 34/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4901 - loss: 0.7163 - val_accuracy: 0.4558 - val_loss: 0.7739\n",
      "Epoch 35/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5244 - loss: 0.7242 - val_accuracy: 0.4490 - val_loss: 0.6974\n",
      "Epoch 36/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4715 - loss: 0.7284 - val_accuracy: 0.4490 - val_loss: 0.7556\n",
      "Epoch 37/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5228 - loss: 0.7133 - val_accuracy: 0.4626 - val_loss: 0.7805\n",
      "Epoch 38/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5524 - loss: 0.7082 - val_accuracy: 0.5374 - val_loss: 0.6940\n",
      "Epoch 39/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5347 - loss: 0.7027 - val_accuracy: 0.4490 - val_loss: 0.7316\n",
      "Epoch 40/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4805 - loss: 0.7607 - val_accuracy: 0.5374 - val_loss: 0.7677\n",
      "Epoch 41/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5700 - loss: 0.6777 - val_accuracy: 0.4762 - val_loss: 0.8723\n",
      "Epoch 42/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4778 - loss: 0.7754 - val_accuracy: 0.5374 - val_loss: 0.6972\n",
      "Epoch 43/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5813 - loss: 0.6809 - val_accuracy: 0.5374 - val_loss: 0.7018\n",
      "Epoch 44/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5527 - loss: 0.6911 - val_accuracy: 0.4490 - val_loss: 0.7342\n",
      "Epoch 45/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5647 - loss: 0.7149 - val_accuracy: 0.5374 - val_loss: 0.6845\n",
      "Epoch 46/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5638 - loss: 0.7215 - val_accuracy: 0.4762 - val_loss: 0.9173\n",
      "Epoch 47/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5514 - loss: 0.7631 - val_accuracy: 0.5374 - val_loss: 0.7033\n",
      "Epoch 48/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5109 - loss: 0.7106 - val_accuracy: 0.4558 - val_loss: 0.7707\n",
      "Epoch 49/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5135 - loss: 0.7536 - val_accuracy: 0.5238 - val_loss: 0.6889\n",
      "Epoch 50/50\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4867 - loss: 0.7225 - val_accuracy: 0.5374 - val_loss: 0.7066\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.4929 - loss: 0.7459 \n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a5cc29d5fe34aa3b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
